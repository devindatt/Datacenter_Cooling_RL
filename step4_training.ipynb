{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step4_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBEDRmtUnllY",
        "outputId": "4f71469b-2fea-4107-9d2c-a74c43bb45ae"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/gdrive')\n",
        "#%cd /gdrive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df_xSHspiYCr",
        "outputId": "ebfe0022-7cdc-4848-aa19-c445016fc5e7"
      },
      "source": [
        "%cd /content/drive/MyDrive/MMAI_845"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MMAI_845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "haiq0kJciX8l",
        "outputId": "2dae2890-cbca-482b-bfc2-ea4d52882103"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/MMAI_845'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9cB0mq-njCL",
        "outputId": "1830b333-141b-4042-a593-7393748aed09"
      },
      "source": [
        "# Training the AI\n",
        "# Installing Keras\n",
        "# conda install -c conda-forge keras\n",
        "\n",
        "# Importing the libraries and the other python files\n",
        "import os\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "import step1_env as environment\n",
        "import step2_buildingbrain as brain\n",
        "import step3_dqn_rl_algo as dqn\n",
        "\n",
        "# Setting seeds for reproducibility \n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "rn.seed(12345)\n",
        "\n",
        "\n",
        "# SETTING THE PARAMETERS\n",
        "epsilon = .3\n",
        "number_actions = 5\n",
        "direction_boundary = (number_actions - 1) / 2\n",
        "number_epochs = 100\n",
        "max_memory = 3000 \n",
        "batch_size = 512 \n",
        "temperature_step = 1.5\n",
        "\n",
        "\n",
        "# BUILDING THE ENVIRONMENT BY SIMPLY CREATING AN OBJECT OF THE ENVIRONMENT CLASS\n",
        "env = environment.Environment(optimal_temperature = (18.0, 24.0),\n",
        "                              initial_month = 0,\n",
        "                              initial_number_users = 20,\n",
        "                              initial_rate_data = 30)\n",
        "\n",
        "# BUILDING THE BRAIN BY SIMPLY CREATING AN OBJECT OF THE BRAIN CLASS\n",
        "brain = brain.Brain(learning_rate = 0.00001, number_actions = number_actions)\n",
        "\n",
        "\n",
        "# BUILDING THE DQN MODEL BY SIMPLY CREATING AN OBJECT OF THE DQN CLASS\n",
        "dqn = dqn.DQN(max_memory = max_memory, discount = 0.9)\n",
        "\n",
        "# CHOOSING THE MODE\n",
        "train = True\n",
        "\n",
        "# TRAINING THE AI\n",
        "env.train = train\n",
        "model = brain.model\n",
        "early_stopping = True\n",
        "patience = 10\n",
        "best_total_reward = -np.inf\n",
        "patience_count = 0\n",
        "\n",
        "\n",
        "if (env.train):\n",
        "\t# STARTING THE LOOP OVER ALL THE EPOCHS (1 Epoch = 5 Months)\n",
        "\tfor epoch in range(1, number_epochs):\n",
        "\t\t# INITIALIAZING ALL THE VARIABLES OF BOTH THE ENVIRONMENT AND THE TRAINING LOOP\n",
        "\t\ttotal_reward = 0\n",
        "\t\tloss = 0.\n",
        "\t\tnew_month = np.random.randint(0, 12)\n",
        "\t\tenv.reset(new_month = new_month)\n",
        "\t\tgame_over = False\n",
        "\t\tcurrent_state, _, _ = env.observe()\n",
        "\t\ttimestep = 0\n",
        "\n",
        "\t\t# STARTING THE LOOP OVER ALL THE TIMESTEPS (1 Timestep = 1 Minute) IN ONE EPOCH\n",
        "\t\twhile ((not game_over) and timestep <= 5 * 30 * 24 * 60):\n",
        "\n",
        "\t\t\t# PLAYING THE NEXT ACTION BY EXPLORATION\n",
        "\t\t\tif np.random.rand() <= epsilon:\n",
        "\t\t\t\taction = np.random.randint(0, number_actions)\n",
        "\t\t\t\tif (action - direction_boundary < 0): \n",
        "\t\t\t\t\tdirection = -1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdirection = 1\n",
        "\t\t\t\tenergy_ai = abs(action - direction_boundary) * temperature_step \n",
        "\n",
        "\n",
        "\t\t\t# PLAYING THE NEXT ACTION BY INFERENCE\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tq_values = model.predict(current_state) \n",
        "\t\t\t\taction = np.argmax(q_values[0])\n",
        "\t\t\t\tif (action - direction_boundary < 0): \n",
        "\t\t\t\t\tdirection = -1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdirection = 1\n",
        "\t\t\t\tenergy_ai = abs(action - direction_boundary) * temperature_step \n",
        "\n",
        "\n",
        "\t\t\t# UPDATING THE ENVIRONMENT AND REACHING THE NEXT STATE\n",
        "\t\t\tnext_state, reward, game_over = env.update_env(direction, energy_ai, int(timestep / (30*24*60)))\n",
        "\n",
        "\n",
        "\t\t\ttotal_reward += reward\n",
        "\t\t\t# STORING THIS NEW TRANSITION INTO THE MEMORY\n",
        "\n",
        "\t\t\tdqn.remember([current_state, action, reward, next_state], game_over)\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t# GATHERING IN TWO SEPARATE BATCHES THE INPUTS AND THE TARGETS\n",
        "\n",
        "\t\t\tinputs, targets = dqn.get_batch(model, batch_size = batch_size)\n",
        "\n",
        "\t\t\t# COMPUTING THE LOSS OVER THE TWO WHOLE BATCHES OF INPUTS AND TARGETS\n",
        "\t\t\tloss += model.train_on_batch(inputs, targets)\n",
        "\t\t\ttimestep += 1\n",
        "\t\t\tcurrent_state = next_state\n",
        "\n",
        "\n",
        "\t\t# PRINTING THE TRAINING RESULTS FOR EACH EPOCH\n",
        "\t\tprint(\"\\n\")\n",
        "\t\tprint(\"Epoch: {:03d}/{:03d}\".format(epoch, number_epochs))\n",
        "\t\tprint(\"Total Energy spent with an AI: {:.0f}\".format(env.total_energy_ai))\n",
        "\t\tprint(\"Total Energy spent with no AI: {:.0f}\".format(env.total_energy_noai)) \n",
        "\n",
        "\t\t# EARLY STOPPING\n",
        "\t\tif (early_stopping):\n",
        "\t\t\tif (total_reward <= best_total_reward):\n",
        "\t\t\t\tpatience_count += 1\n",
        "\t\t\telif (total_reward > best_total_reward):\n",
        "\t\t\t\tbest_total_reward = total_reward\n",
        "\t\t\t\tpatience_count = 0\n",
        "\t\t\n",
        "\t\tif (patience_count >= patience):\n",
        "\t\t\tprint(\"Early Stopping\")\n",
        "\t\t\tbreak\n",
        "\t\t\n",
        "\t\t# SAVING THE MODEL\n",
        "\t\tmodel.save(\"model.h5\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch: 001/100\n",
            "Total Energy spent with an AI: 32\n",
            "Total Energy spent with no AI: 69\n",
            "\n",
            "\n",
            "Epoch: 002/100\n",
            "Total Energy spent with an AI: 42\n",
            "Total Energy spent with no AI: 36\n",
            "\n",
            "\n",
            "Epoch: 003/100\n",
            "Total Energy spent with an AI: 9\n",
            "Total Energy spent with no AI: 6\n",
            "\n",
            "\n",
            "Epoch: 004/100\n",
            "Total Energy spent with an AI: 14\n",
            "Total Energy spent with no AI: 43\n",
            "\n",
            "\n",
            "Epoch: 005/100\n",
            "Total Energy spent with an AI: 9\n",
            "Total Energy spent with no AI: 14\n",
            "\n",
            "\n",
            "Epoch: 006/100\n",
            "Total Energy spent with an AI: 33\n",
            "Total Energy spent with no AI: 62\n",
            "\n",
            "\n",
            "Epoch: 007/100\n",
            "Total Energy spent with an AI: 38\n",
            "Total Energy spent with no AI: 49\n",
            "\n",
            "\n",
            "Epoch: 008/100\n",
            "Total Energy spent with an AI: 15\n",
            "Total Energy spent with no AI: 56\n",
            "\n",
            "\n",
            "Epoch: 009/100\n",
            "Total Energy spent with an AI: 3\n",
            "Total Energy spent with no AI: 0\n",
            "\n",
            "\n",
            "Epoch: 010/100\n",
            "Total Energy spent with an AI: 56\n",
            "Total Energy spent with no AI: 65\n",
            "\n",
            "\n",
            "Epoch: 011/100\n",
            "Total Energy spent with an AI: 21\n",
            "Total Energy spent with no AI: 25\n",
            "\n",
            "\n",
            "Epoch: 012/100\n",
            "Total Energy spent with an AI: 20\n",
            "Total Energy spent with no AI: 34\n",
            "\n",
            "\n",
            "Epoch: 013/100\n",
            "Total Energy spent with an AI: 45\n",
            "Total Energy spent with no AI: 82\n",
            "\n",
            "\n",
            "Epoch: 014/100\n",
            "Total Energy spent with an AI: 40\n",
            "Total Energy spent with no AI: 44\n",
            "\n",
            "\n",
            "Epoch: 015/100\n",
            "Total Energy spent with an AI: 6\n",
            "Total Energy spent with no AI: 1\n",
            "\n",
            "\n",
            "Epoch: 016/100\n",
            "Total Energy spent with an AI: 63\n",
            "Total Energy spent with no AI: 108\n",
            "\n",
            "\n",
            "Epoch: 017/100\n",
            "Total Energy spent with an AI: 9\n",
            "Total Energy spent with no AI: 34\n",
            "\n",
            "\n",
            "Epoch: 018/100\n",
            "Total Energy spent with an AI: 8\n",
            "Total Energy spent with no AI: 20\n",
            "\n",
            "\n",
            "Epoch: 019/100\n",
            "Total Energy spent with an AI: 38\n",
            "Total Energy spent with no AI: 44\n",
            "\n",
            "\n",
            "Epoch: 020/100\n",
            "Total Energy spent with an AI: 22\n",
            "Total Energy spent with no AI: 60\n",
            "\n",
            "\n",
            "Epoch: 021/100\n",
            "Total Energy spent with an AI: 4\n",
            "Total Energy spent with no AI: 13\n",
            "\n",
            "\n",
            "Epoch: 022/100\n",
            "Total Energy spent with an AI: 10\n",
            "Total Energy spent with no AI: 16\n",
            "\n",
            "\n",
            "Epoch: 023/100\n",
            "Total Energy spent with an AI: 4\n",
            "Total Energy spent with no AI: 12\n",
            "Early Stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITHA0uYciTgj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}